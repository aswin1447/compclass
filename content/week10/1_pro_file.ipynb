{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 Day 1: (Pro)file\n",
    "\n",
    "## Objectives\n",
    "\n",
    "* Cover profiling (extension of last lecture)\n",
    "* Cover reading and writing of files\n",
    "* Start the basics of ODEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling\n",
    "\n",
    "Quick extension of last week's lecture: Remember we said that you should optimize only the slow parts of your program. How do you tell? Profile!\n",
    "\n",
    "There are two types of profilers:\n",
    "1. Deterministic profilers: These modify the runtime of the program by tracking every line.\n",
    "2. Sampling profilers: These \"sample\" every so often.\n",
    "\n",
    "The main profiler for Python is the built in `cProfile` and `profile` modules (the first being a faster version of the second). Since Python is already interpreted and slow, most profilers for Python are deterministic profilers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example uses the built in profiler directly, as well as `line_profiler`, from either conda (`conda install line_profiler` in environment) or pip (`pip install --user line-profiler`). Line profiler is a powerful, better interface (and IPython extension) for the cProfile module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def sampler(\n",
    "    data,\n",
    "    samples=4,\n",
    "    mu_init=0.5,\n",
    "    proposal_width=0.5,\n",
    "    plot=False,\n",
    "    mu_prior_mu=0,\n",
    "    mu_prior_sd=1.0,\n",
    "):\n",
    "    mu_current = mu_init\n",
    "    posterior = [mu_current]\n",
    "    for i in range(samples):\n",
    "        # suggest new position\n",
    "        mu_proposal = norm(mu_current, proposal_width).rvs()\n",
    "\n",
    "        # Compute likelihood by multiplying probabilities of each data point\n",
    "        likelihood_current = norm(mu_current, 1).pdf(data).prod()\n",
    "        likelihood_proposal = norm(mu_proposal, 1).pdf(data).prod()\n",
    "\n",
    "        # Compute prior probability of current and proposed mu\n",
    "        prior_current = norm(mu_prior_mu, mu_prior_sd).pdf(mu_current)\n",
    "        prior_proposal = norm(mu_prior_mu, mu_prior_sd).pdf(mu_proposal)\n",
    "\n",
    "        p_current = likelihood_current * prior_current\n",
    "        p_proposal = likelihood_proposal * prior_proposal\n",
    "\n",
    "        # Accept proposal?\n",
    "        p_accept = p_proposal / p_current\n",
    "\n",
    "        # Usually would include prior probability, which we neglect here for simplicity\n",
    "        accept = np.random.rand() < p_accept\n",
    "\n",
    "        if plot:\n",
    "            plot_proposal(\n",
    "                mu_current,\n",
    "                mu_proposal,\n",
    "                mu_prior_mu,\n",
    "                mu_prior_sd,\n",
    "                data,\n",
    "                accept,\n",
    "                posterior,\n",
    "                i,\n",
    "            )\n",
    "\n",
    "        if accept:\n",
    "            # Update position\n",
    "            mu_current = mu_proposal\n",
    "\n",
    "        posterior.append(mu_current)\n",
    "\n",
    "    return posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "data = np.random.randn(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         7334008 function calls (7282008 primitive calls) in 4.889 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     2000    0.002    0.000    0.027    0.000 <__array_function__ internals>:2(all)\n",
      "     4000    0.004    0.000    0.061    0.000 <__array_function__ internals>:2(any)\n",
      "     4000    0.004    0.000    0.042    0.000 <__array_function__ internals>:2(atleast_1d)\n",
      "     1000    0.001    0.000    0.020    0.000 <__array_function__ internals>:2(broadcast_arrays)\n",
      "     8000    0.006    0.000    0.168    0.000 <__array_function__ internals>:2(extract)\n",
      "     8000    0.005    0.000    0.028    0.000 <__array_function__ internals>:2(nonzero)\n",
      "     4000    0.003    0.000    0.019    0.000 <__array_function__ internals>:2(place)\n",
      "     4000    0.004    0.000    0.018    0.000 <__array_function__ internals>:2(putmask)\n",
      "    16000    0.011    0.000    0.066    0.000 <__array_function__ internals>:2(ravel)\n",
      "     4000    0.005    0.000    0.013    0.000 <__array_function__ internals>:2(shape)\n",
      "     8000    0.005    0.000    0.038    0.000 <__array_function__ internals>:2(take)\n",
      "        1    0.016    0.016    4.897    4.897 <ipython-input-2-17c343ae0e58>:1(sampler)\n",
      "        1    0.000    0.000    4.897    4.897 <string>:1(<module>)\n",
      "    15000    0.008    0.000    0.013    0.000 <string>:1(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:2(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 <string>:2(_parse_args)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:5(_parse_args_rvs)\n",
      "    16000    0.006    0.000    0.031    0.000 _asarray.py:16(asarray)\n",
      "    24000    0.007    0.000    0.019    0.000 _asarray.py:88(asanyarray)\n",
      "     4000    0.038    0.000    0.038    0.000 _continuous_distns.py:179(_norm_pdf)\n",
      "     1000    0.001    0.000    0.005    0.000 _continuous_distns.py:234(_rvs)\n",
      "     4000    0.003    0.000    0.041    0.000 _continuous_distns.py:237(_pdf)\n",
      "     5000    0.119    0.000    3.976    0.001 _distn_infrastructure.py:1572(__init__)\n",
      "     5000    0.007    0.000    0.009    0.000 _distn_infrastructure.py:1637(_updated_ctor_param)\n",
      "     4000    0.186    0.000    0.732    0.000 _distn_infrastructure.py:1714(pdf)\n",
      "     5000    0.035    0.000    4.025    0.001 _distn_infrastructure.py:423(__init__)\n",
      "    15000    0.007    0.000    0.007    0.000 _distn_infrastructure.py:44(instancemethod)\n",
      "     4000    0.010    0.000    0.742    0.000 _distn_infrastructure.py:442(pdf)\n",
      "     1000    0.003    0.000    0.088    0.000 _distn_infrastructure.py:460(rvs)\n",
      "     4000    0.012    0.000    0.253    0.000 _distn_infrastructure.py:520(argsreduce)\n",
      "     4000    0.031    0.000    0.199    0.000 _distn_infrastructure.py:545(<listcomp>)\n",
      "     5000    0.016    0.000    0.297    0.000 _distn_infrastructure.py:587(__init__)\n",
      "     5000    0.057    0.000    1.005    0.000 _distn_infrastructure.py:622(_construct_argparser)\n",
      "     5000    0.054    0.000    2.509    0.001 _distn_infrastructure.py:702(_construct_doc)\n",
      "     5000    0.001    0.000    0.001    0.000 _distn_infrastructure.py:710(<genexpr>)\n",
      "     5000    0.006    0.000    4.031    0.001 _distn_infrastructure.py:753(freeze)\n",
      "     5000    0.004    0.000    4.036    0.001 _distn_infrastructure.py:770(__call__)\n",
      "     1000    0.005    0.000    0.028    0.000 _distn_infrastructure.py:790(_argcheck_rvs)\n",
      "     2000    0.001    0.000    0.001    0.000 _distn_infrastructure.py:804(squeeze_left)\n",
      "     1000    0.001    0.000    0.002    0.000 _distn_infrastructure.py:820(<listcomp>)\n",
      "     1000    0.000    0.000    0.000    0.000 _distn_infrastructure.py:849(<listcomp>)\n",
      "    10000    0.003    0.000    0.003    0.000 _distn_infrastructure.py:864(_argcheck)\n",
      "     9000    0.003    0.000    0.003    0.000 _distn_infrastructure.py:876(_get_support)\n",
      "     4000    0.018    0.000    0.019    0.000 _distn_infrastructure.py:897(_support_mask)\n",
      "     1000    0.022    0.000    0.084    0.000 _distn_infrastructure.py:935(rvs)\n",
      "     2000    0.001    0.000    0.011    0.000 _methods.py:40(_prod)\n",
      "     2000    0.001    0.000    0.013    0.000 _methods.py:44(_any)\n",
      "     2000    0.001    0.000    0.009    0.000 _methods.py:47(_all)\n",
      "     5000    0.004    0.000    0.004    0.000 _util.py:174(check_random_state)\n",
      "    15000    0.078    0.000    0.707    0.000 _util.py:277(getargspec_no_self)\n",
      "    15000    0.012    0.000    0.014    0.000 _util.py:300(<listcomp>)\n",
      "    15000    0.007    0.000    0.008    0.000 _util.py:304(<listcomp>)\n",
      "    15000    0.006    0.000    0.007    0.000 _util.py:309(<listcomp>)\n",
      "    15000    0.009    0.000    0.012    0.000 _util.py:314(<listcomp>)\n",
      "    10000    0.815    0.000    2.253    0.000 doccer.py:12(docformat)\n",
      "    10000    0.280    0.000    0.505    0.000 doccer.py:179(indentcount_lines)\n",
      "    25000    0.019    0.000    0.026    0.000 enum.py:284(__call__)\n",
      "    25000    0.007    0.000    0.007    0.000 enum.py:526(__new__)\n",
      "    16000    0.002    0.000    0.002    0.000 fromnumeric.py:1689(_ravel_dispatcher)\n",
      "    16000    0.016    0.000    0.045    0.000 fromnumeric.py:1693(ravel)\n",
      "     8000    0.001    0.000    0.001    0.000 fromnumeric.py:1800(_nonzero_dispatcher)\n",
      "     8000    0.004    0.000    0.019    0.000 fromnumeric.py:1804(nonzero)\n",
      "     4000    0.001    0.000    0.001    0.000 fromnumeric.py:1899(_shape_dispatcher)\n",
      "     4000    0.002    0.000    0.002    0.000 fromnumeric.py:1903(shape)\n",
      "     4000    0.001    0.000    0.001    0.000 fromnumeric.py:2232(_any_dispatcher)\n",
      "     4000    0.006    0.000    0.053    0.000 fromnumeric.py:2236(any)\n",
      "     2000    0.000    0.000    0.000    0.000 fromnumeric.py:2320(_all_dispatcher)\n",
      "     2000    0.002    0.000    0.022    0.000 fromnumeric.py:2324(all)\n",
      "    16000    0.010    0.000    0.034    0.000 fromnumeric.py:55(_wrapfunc)\n",
      "     6000    0.017    0.000    0.066    0.000 fromnumeric.py:73(_wrapreduction)\n",
      "     6000    0.003    0.000    0.003    0.000 fromnumeric.py:74(<dictcomp>)\n",
      "     8000    0.001    0.000    0.001    0.000 fromnumeric.py:93(_take_dispatcher)\n",
      "     8000    0.007    0.000    0.027    0.000 fromnumeric.py:97(take)\n",
      "     8000    0.002    0.000    0.002    0.000 function_base.py:1624(_extract_dispatcher)\n",
      "     8000    0.022    0.000    0.154    0.000 function_base.py:1628(extract)\n",
      "     4000    0.001    0.000    0.001    0.000 function_base.py:1680(_place_dispatcher)\n",
      "     4000    0.003    0.000    0.012    0.000 function_base.py:1684(place)\n",
      "    20000    0.044    0.000    0.046    0.000 function_base.py:2031(__init__)\n",
      "    30000    0.009    0.000    0.012    0.000 inspect.py:158(isfunction)\n",
      "    15000    0.046    0.000    0.136    0.000 inspect.py:1799(_signature_bound_method)\n",
      "    15000    0.098    0.000    0.251    0.000 inspect.py:2117(_signature_from_function)\n",
      "30000/15000    0.090    0.000    0.531    0.000 inspect.py:2198(_signature_from_callable)\n",
      "    25000    0.043    0.000    0.076    0.000 inspect.py:2467(__init__)\n",
      "    45000    0.006    0.000    0.006    0.000 inspect.py:2517(name)\n",
      "    20000    0.002    0.000    0.002    0.000 inspect.py:2521(default)\n",
      "    80000    0.009    0.000    0.009    0.000 inspect.py:2529(kind)\n",
      "    30000    0.102    0.000    0.124    0.000 inspect.py:2750(__init__)\n",
      "    40000    0.014    0.000    0.018    0.000 inspect.py:2799(<genexpr>)\n",
      "    15000    0.019    0.000    0.550    0.000 inspect.py:2829(from_callable)\n",
      "    75000    0.008    0.000    0.008    0.000 inspect.py:2835(parameters)\n",
      "    15000    0.016    0.000    0.079    0.000 inspect.py:2843(replace)\n",
      "    15000    0.010    0.000    0.560    0.000 inspect.py:3081(signature)\n",
      "    15000    0.022    0.000    0.036    0.000 inspect.py:484(unwrap)\n",
      "    15000    0.005    0.000    0.008    0.000 inspect.py:504(_is_wrapper)\n",
      "     4000    0.001    0.000    0.001    0.000 multiarray.py:1078(putmask)\n",
      "     8000    0.051    0.000    0.068    0.000 numerictypes.py:578(_can_coerce_all)\n",
      "    56000    0.012    0.000    0.012    0.000 numerictypes.py:587(<listcomp>)\n",
      "     4000    0.010    0.000    0.084    0.000 numerictypes.py:602(find_common_type)\n",
      "     4000    0.005    0.000    0.005    0.000 numerictypes.py:654(<listcomp>)\n",
      "     4000    0.001    0.000    0.001    0.000 numerictypes.py:655(<listcomp>)\n",
      "     4000    0.001    0.000    0.001    0.000 shape_base.py:21(_atleast_1d_dispatcher)\n",
      "     4000    0.014    0.000    0.034    0.000 shape_base.py:25(atleast_1d)\n",
      "     1000    0.004    0.000    0.004    0.000 stride_tricks.py:185(_broadcast_shape)\n",
      "     1000    0.000    0.000    0.000    0.000 stride_tricks.py:202(_broadcast_arrays_dispatcher)\n",
      "     1000    0.004    0.000    0.016    0.000 stride_tricks.py:206(broadcast_arrays)\n",
      "     1000    0.001    0.000    0.006    0.000 stride_tricks.py:262(<listcomp>)\n",
      "     3000    0.001    0.000    0.001    0.000 stride_tricks.py:266(<genexpr>)\n",
      "    15000    0.006    0.000    0.006    0.000 {built-in method __new__ of type object at 0x55e26f98c240}\n",
      "     2000    0.001    0.000    0.002    0.000 {built-in method builtins.all}\n",
      "    30000    0.004    0.000    0.004    0.000 {built-in method builtins.callable}\n",
      "   5001/1    0.500    0.000    4.897    4.897 {built-in method builtins.exec}\n",
      "    20000    0.005    0.000    0.005    0.000 {built-in method builtins.getattr}\n",
      "    20000    0.004    0.000    0.004    0.000 {built-in method builtins.hasattr}\n",
      "    15000    0.003    0.000    0.003    0.000 {built-in method builtins.id}\n",
      "   144000    0.020    0.000    0.020    0.000 {built-in method builtins.isinstance}\n",
      "  1045000    0.071    0.000    0.071    0.000 {built-in method builtins.len}\n",
      "   480000    0.091    0.000    0.091    0.000 {built-in method builtins.min}\n",
      "    15000    0.004    0.000    0.004    0.000 {built-in method builtins.setattr}\n",
      "    42000    0.041    0.000    0.041    0.000 {built-in method numpy.array}\n",
      "     4000    0.008    0.000    0.008    0.000 {built-in method numpy.core._multiarray_umath._insert}\n",
      "63000/31000    0.057    0.000    0.333    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "     4000    0.004    0.000    0.004    0.000 {built-in method numpy.zeros}\n",
      "    15000    0.003    0.000    0.003    0.000 {built-in method sys.getrecursionlimit}\n",
      "     2000    0.003    0.000    0.012    0.000 {method 'all' of 'numpy.generic' objects}\n",
      "     2000    0.005    0.000    0.018    0.000 {method 'any' of 'numpy.generic' objects}\n",
      "  2464000    0.177    0.000    0.177    0.000 {method 'append' of 'list' objects}\n",
      "    11000    0.006    0.000    0.006    0.000 {method 'copy' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   320000    0.356    0.000    0.356    0.000 {method 'expandtabs' of 'str' objects}\n",
      "    46000    0.008    0.000    0.008    0.000 {method 'get' of 'dict' objects}\n",
      "    25000    0.005    0.000    0.005    0.000 {method 'isidentifier' of 'str' objects}\n",
      "    16000    0.003    0.000    0.003    0.000 {method 'items' of 'dict' objects}\n",
      "   275000    0.089    0.000    0.090    0.000 {method 'join' of 'str' objects}\n",
      "   655000    0.072    0.000    0.072    0.000 {method 'lstrip' of 'str' objects}\n",
      "     8000    0.007    0.000    0.007    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
      "     3000    0.001    0.000    0.001    0.000 {method 'pop' of 'dict' objects}\n",
      "     2000    0.002    0.000    0.013    0.000 {method 'prod' of 'numpy.ndarray' objects}\n",
      "     1000    0.003    0.000    0.003    0.000 {method 'rand' of 'numpy.random.mtrand.RandomState' objects}\n",
      "    16000    0.012    0.000    0.012    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "     8000    0.043    0.000    0.043    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "    30000    0.191    0.000    0.191    0.000 {method 'replace' of 'str' objects}\n",
      "     6000    0.012    0.000    0.012    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "   320000    0.320    0.000    0.320    0.000 {method 'splitlines' of 'str' objects}\n",
      "     1000    0.004    0.000    0.004    0.000 {method 'standard_normal' of 'numpy.random.mtrand.RandomState' objects}\n",
      "     8000    0.014    0.000    0.014    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "     1000    0.001    0.000    0.001    0.000 {method 'update' of 'dict' objects}\n",
      "    75000    0.014    0.000    0.014    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run(\"posterior = sampler(data, samples=1000, mu_init=1.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading that last page is a bit tricky - we have the \"insides\" of all the Python functions being called. Let's try `line_profiler` to just select the *one* function we care about, and see that line-by-line.\n",
    "\n",
    "Like all external packages except matplotlib, we need to load the package as an IPython extension first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can use the `lprun` magic along with the `-f function` to select a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f sampler posterior = sampler(data, samples=1000, mu_init=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! I can easily see what's wrong now. This allows you to *target* optimizations; often minor changes, like `np.stack` instead of `np.array`, may give you large speedups. Parts that are not performance critical can remain clear and easy to read/maintain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real life example:\n",
    "* I had 128 DataFrames of around a million events each, and I wanted to make 128 2D histograms.\n",
    "* Custom Histogram library Physt was taking 3 seconds per histogram.\n",
    "* Native Numpy histogram (then feeding that into Physt) took .9 seconds per histogram.\n",
    "* Custom Numba histogram function (then feeding that into Physt) took 0.1 seconds per histogram.\n",
    "\n",
    "At this point, a total of 10-15 seconds for the procedure was fine. Physt histograms as output means I can use the nice OO design to merge and rebin histograms later, by the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files\n",
    "\n",
    "Let's look at reading in and out data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic input/output\n",
    "\n",
    "As a reminder, this is input output of text or data files in pure Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is one line\n",
      "Second line\n"
     ]
    }
   ],
   "source": [
    "with open(\"tmpfile.txt\", \"w\") as f:\n",
    "    f.write(\"This is one line\\n\")\n",
    "    print(\"Second line\", file=f)\n",
    "# File gets closed here\n",
    "\n",
    "with open(\"tmpfile.txt\") as f:\n",
    "    for l in f:\n",
    "        print(l, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can iterate over a file to get lines, or use `.readlines` to get a list of lines, or `.read` to just read in (part) of the file. The mode flags can set text vs. binary `'b'`, read `'r'`, write `'w'`, or append `'a'`.\n",
    "\n",
    "The `f` object is a File Buffer. Quite a few functions and libraries in Python take a buffer - usually they take a file name or an open buffer. You can make a buffer that is attached to your memory instead of a file with `io.StringIO`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serializing any objects\n",
    "\n",
    "Python has a protocol for storing and recovering almost any object called \"pickling\". This is general purpose, but is often not ideal for large or long term storage, or for communicating data - there is some limitation on Python version, the class code should be similar or the same, and there is no compression. But, it can be handy in a pinch. You can use `dump` and `load`, or you can use `dumps` and `loads` to input/output directly to a string instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x80\\x03X\\x0b\\x00\\x00\\x00some objectq\\x00.'\n"
     ]
    }
   ],
   "source": [
    "pickle_str = pickle.dumps(\"some object\")\n",
    "print(pickle_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'some object'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.loads(pickle_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use case: configuration\n",
    "\n",
    "Let's look at better ways to do IO for specific cases. Let's look at a common one: storing some \"configuration\" like data (or any small set of data). As long as the data is small, it's nice to leave it human readable format, in a text file. Here are some popular formats:\n",
    "\n",
    "1. **XML**: Famous - HTML is a subset of XML. Very verbose and ugly, and often used with a custom schema.\n",
    "2. **JSON**: Popular. A little unfriendly for writing, but clean and simple. A subset of JavaScript makes it web-friendly. Great libraries available.\n",
    "3. **INI**: Not well defined, and *very* limited. Very easy for a human to author, though.\n",
    "4. **YAML**: Yet Another Markup Language, popular in some areas. Lots of weird corner cases to the syntax, though.\n",
    "5. **TOML**: Simpler version of the thing above. Gaining some use in Python as of late.\n",
    "\n",
    "Of these, the best standard library support in Python goes to JSON, so we'll look at that one. It's the best in the list for (small amounts of) general data. For configuration, it's a tossup.\n",
    "\n",
    "JSON has the same methods as pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " \"list\",\n",
      " \"items\",\n",
      " {\n",
      "  \"dictionary\": \"Nested\",\n",
      "  \"number\": 2\n",
      " }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "structure_to_save = [\"list\", \"items\", {\"dictionary\": \"Nested\", \"number\": 2}]\n",
    "\n",
    "print(json.dumps(structure_to_save, indent=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read more at [Python 3 Module of the Week](https://pymotw.com/3/index.html): [json](https://pymotw.com/3/json/index.html>) or the [official documentation](https://docs.python.org/3/library/json.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger data storage\n",
    "#### Numpy\n",
    "Let's assume we have data in Numpy. We can use one of several Numpy methods to store the data; we can even compress it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format is a simple binary one-array-per-file format; you can use `savez` to save several files into one uncompressed zip file, or `savez_compressed` to save to a compressed zip file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"tmp.npz\", a=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "with np.load(\"tmp.npz\") as f:\n",
    "    print(f[\"a\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While simple, this is still Numpy specific, and is not ideal for cross-language data storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDF5\n",
    "\n",
    "This is a standard format for storing binary structured data with optional compression. It has several nice features, like groups and attributes, that make it very powerful. You need an external library, but Anaconda comes with it by default. Technically, it comes with two. H5py and PyTables; I use HDF5 in C++ also, so I like the fact that H5py looks more like other HDF5 libraries, so I'll cover that. The other one is available with `import tables`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/miniconda/envs/compclass/lib/python3.7/site-packages/ipykernel_launcher.py:4: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/share/miniconda/envs/compclass/lib/python3.7/site-packages/ipykernel_launcher.py:5: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"tmp.h5\", \"w\") as f:\n",
    "    f[\"a\"] = a\n",
    "\n",
    "with h5py.File(\"tmp.h5\") as f:\n",
    "    b = f[\"a\"].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(a == b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a common idiom in modern IO libraries; you treat the file like a dictionary. There are explicit methods if you need to do something fancier (like turn on compression for a dataset). HDF5 has tools to allow you to keep a dataset on file instead of reading it entirely to memory (but I've not had to use those)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, there are great non-Python tools for HDF5 available, like a graphical file viewer.\n",
    "\n",
    "<font color=\"grey\">\n",
    "\n",
    "> Note for HEP physicists: the ROOT file format has a few features that HDF5 does not, like incremental saving. However, other than small differences, the formats are similar. Except that HDF5 is available everywhere and even if it isn't, it takes something like 5 minutes to build instead of several hours...\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas\n",
    "\n",
    "Pandas has very powerful connectors to lots of different formats, including CSV, JSON, Excel, and HDF5. If your data is already a table, just use Pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>-0.455285</td>\n",
       "      <td>0.130549</td>\n",
       "      <td>-2.285845</td>\n",
       "      <td>2.360208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>0.259258</td>\n",
       "      <td>0.256923</td>\n",
       "      <td>0.780788</td>\n",
       "      <td>0.561676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>1.437854</td>\n",
       "      <td>1.700878</td>\n",
       "      <td>-0.816026</td>\n",
       "      <td>-1.941486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.696014</td>\n",
       "      <td>2.202473</td>\n",
       "      <td>-1.077163</td>\n",
       "      <td>1.505113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-1.066637</td>\n",
       "      <td>1.296895</td>\n",
       "      <td>1.286712</td>\n",
       "      <td>0.233670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>-0.637027</td>\n",
       "      <td>1.150314</td>\n",
       "      <td>-0.552488</td>\n",
       "      <td>1.561838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-01 -0.455285  0.130549 -2.285845  2.360208\n",
       "2013-01-02  0.259258  0.256923  0.780788  0.561676\n",
       "2013-01-03  1.437854  1.700878 -0.816026 -1.941486\n",
       "2013-01-04 -1.696014  2.202473 -1.077163  1.505113\n",
       "2013-01-05 -1.066637  1.296895  1.286712  0.233670\n",
       "2013-01-06 -0.637027  1.150314 -0.552488  1.561838"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.date_range(\"20130101\", periods=6)\n",
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list(\"ABCD\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf(\"tmp.h5\", \"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>-0.455285</td>\n",
       "      <td>0.130549</td>\n",
       "      <td>-2.285845</td>\n",
       "      <td>2.360208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>0.259258</td>\n",
       "      <td>0.256923</td>\n",
       "      <td>0.780788</td>\n",
       "      <td>0.561676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>1.437854</td>\n",
       "      <td>1.700878</td>\n",
       "      <td>-0.816026</td>\n",
       "      <td>-1.941486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.696014</td>\n",
       "      <td>2.202473</td>\n",
       "      <td>-1.077163</td>\n",
       "      <td>1.505113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-1.066637</td>\n",
       "      <td>1.296895</td>\n",
       "      <td>1.286712</td>\n",
       "      <td>0.233670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>-0.637027</td>\n",
       "      <td>1.150314</td>\n",
       "      <td>-0.552488</td>\n",
       "      <td>1.561838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-01 -0.455285  0.130549 -2.285845  2.360208\n",
       "2013-01-02  0.259258  0.256923  0.780788  0.561676\n",
       "2013-01-03  1.437854  1.700878 -0.816026 -1.941486\n",
       "2013-01-04 -1.696014  2.202473 -1.077163  1.505113\n",
       "2013-01-05 -1.066637  1.296895  1.286712  0.233670\n",
       "2013-01-06 -0.637027  1.150314 -0.552488  1.561838"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_hdf(\"tmp.h5\", \"df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus: Uproot\n",
    "\n",
    "In HEP, we have a very commonly used and powerful format: ROOT. But getting ROOT to compile is a long (2+ hour) ordeal, and I have yet to get it to work with Anaconda Python on macOS.\n",
    "\n",
    "An exciting new library, \"uproot\" lets you read ROOT files in pure Python without ROOT. The original name was to be micro-root, or $\\mu$root, but it became uproot. You've already seen a bit of uproot in the previous lectures.\n",
    "\n",
    "Writing files is planned, but still in progress."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compclass",
   "language": "python",
   "name": "compclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
